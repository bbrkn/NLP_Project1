{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries to get data\n",
    "import urllib.request \n",
    "import re \n",
    "import io \n",
    "import zlib \n",
    "import json \n",
    "# libraries for nlp datapreprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "# libraries for nn model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take categories\n",
    "menu_numbers = [] # menu url \n",
    "categories = [] # category list\n",
    "for menu_number in menu_numbers:\n",
    "    url = \"url\" + menu_number\n",
    "    headers = {'headers'}\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    try:\n",
    "        answer = urllib.request.urlopen(request)\n",
    "        htmlBytes=zlib.decompress(answer.read(), 16+zlib.MAX_WBITS)\n",
    "        htmlStr = htmlBytes.decode(\"utf-8\")\n",
    "        json_answer = json.loads(htmlStr)\n",
    "        \n",
    "        category_level_1 = [] \n",
    "        category_level_2 = [] \n",
    "        category_level_3 = [] \n",
    "        category_level_4 = []\n",
    "        \n",
    "        for item in json_answer[\"items\"]:\n",
    "            for child in item[\"children\"]:\n",
    "                if(child[\"url\"]): # url var ise\n",
    "                    category_level_1.append(child[\"url\"])\n",
    "                for child2 in child[\"children\"]:\n",
    "                    if (child2[\"url\"]):\n",
    "                        category_level_2.append(child2[\"url\"])\n",
    "                    if (len(child2[\"children\"]) > 0):\n",
    "                        for child3 in child2[\"children\"]:\n",
    "                            if (child3[\"url\"]):\n",
    "                                category_level_3.append(child3[\"url\"])\n",
    "                                for child4 in child3[\"children\"]:\n",
    "                                    if (child4[\"url\"]):\n",
    "                                        category_level_4.append(child4[\"url\"])\n",
    "        categories.append(category_level_1)\n",
    "        categories.append(category_level_2)\n",
    "        categories.append(category_level_3)\n",
    "        categories.append(category_level_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = []  \n",
    "\n",
    "for category in categories:\n",
    "    for category1 in category:\n",
    "        category_list.append(category1.split(\"?\")[0]) # fix ? errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"category_list.txt\", \"w\") as txt_file: # take backup category urls\n",
    "    for line in category_list:\n",
    "        txt_file.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = set() # set for take items one time\n",
    "comments = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take items in categories\n",
    "for num2 in range(len(category_list)): \n",
    "    new_url = url + category_list[num2] \n",
    "    \n",
    "    htmlStr = requests.get(new_url, headers=headers).text\n",
    "\n",
    "    wanted = '<a href=\"(.*?)-c-(.*?)sayfa=(.*?)\" class=\"page-(.*?)\">(.*?)</a>' \n",
    "\n",
    "    pages = re.findall(wanted, htmlStr)\n",
    "    if len(pages) > 0: \n",
    "        page_number = int(pages[-1][2]) \n",
    "        page = 1\n",
    "        for num in range(page_number):\n",
    "            url2 = new_url + '?sayfa=' + str(num + 1) \n",
    "            try:\n",
    "                htmlStr2 = requests.get(url2, headers=headers).text\n",
    "            except:\n",
    "                print(\"something wrong\")\n",
    "\n",
    "            wanted2 = '\"(.*?)\"\\r\\n        data-sku=\"(.*?)\"'  \n",
    "            pages2 = re.findall(wanted2, htmlStr2)\n",
    "\n",
    "            for item in pages2:\n",
    "                if item[0] not in items:\n",
    "                    items.add(item[0]) \n",
    "    else: \n",
    "        url3 = new_url\n",
    "        print(url3)\n",
    "        try:\n",
    "            htmlStr3 = requests.get(url3, headers=headers).text\n",
    "        except:\n",
    "            print(\"something wrong\")\n",
    "\n",
    "        wanted3 = '\"(.*?)\"\\r\\n        data-sku=\"(.*?)\"'\n",
    "        pages3 = re.findall(wanted3, htmlStr3)\n",
    "\n",
    "        for word in pages3:\n",
    "            if word[0] not in items:\n",
    "                items.add(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"item_list_1.txt\", \"w\") as txt_file:  # take backup item urls\n",
    "    for line in items:\n",
    "        txt_file.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turkish_char(word): # fix turkish characters\n",
    "    return word.replace(\"&#252;\",\"ü\").replace(\"&#220;\",\"Ü\").replace(\"&#231;\",\"ç\").replace(\"&#199;\",\"Ç\").replace(\"&#246;\",\"ö\").replace(\"&#214;\",\"Ö\").replace(\"&#39;\",\"'\")\n",
    "\n",
    "def nobrackets(word): # fix brackets\n",
    "    return word.replace(\"(\",\"\").replace(\")\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in items:\n",
    "    new_url = url + line + \"yorumlari\"\n",
    "\n",
    "    htmlStr = requests.get(new_url, headers=headers).text\n",
    "    page_pattern = '<span class=\"hermes-PageHolder-module-1QoWq\">(.*?)</span>' # page numbers\n",
    "    pages = re.findall(page_pattern, htmlStr)\n",
    "    if pages == []:\n",
    "        page_number = 1\n",
    "    else:\n",
    "        page_number = int(pages[-1])\n",
    "\n",
    "    for page in range(page_number):\n",
    "        new_url = url + line + \"-yorumlari\" + \"?sayfa=\" + str(page+1)\n",
    "\n",
    "        htmlStr = requests.get(new_url, headers=headers).text\n",
    "\n",
    "\n",
    "        comm_pattern = '<span itemProp=\\\\\"description\\\\\">(.*?)</span>'  \n",
    "        comment = re.findall(comm_pattern, htmlStr, re.MULTILINE|re.DOTALL)\n",
    "        score_pattern ='<span itemProp=\"ratingValue\" content=\"(.*?)\"></span>' \n",
    "        score = re.findall(score_pattern, htmlStr, re.MULTILINE|re.DOTALL)\n",
    "\n",
    "        if (comment != []):\n",
    "            for i in range(len(comment)):\n",
    "                comm = comment[i].replace('\\n','').replace('\\r','').replace('  ','')\n",
    "                comm = emoji_pattern.sub(r'', comm)\n",
    "                score1 = score[i]\n",
    "\n",
    "                comment0 = (score1, nobrackets(turkish_char(comm)))\n",
    "                comments.add(comment0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"comment_list_1.csv\", \"w\", encoding=\"utf-8\") as txt_file: # take backup comments\n",
    "    for line in comments:\n",
    "        txt_file.write(str(line[0]) + \"\\t\" + str(line[1]).replace(\"\\t\", \" \") + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"comment_list_1.csv\", sep = \"\\t\", names =[\"Score\",\"Comments\"])\n",
    "df = data.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='any',axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    118181\n",
      "4     27931\n",
      "3     12898\n",
      "1      8484\n",
      "2      4937\n",
      "Name: Score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Score\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(df[\"Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments1 = df[\"Comments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " #  remove punctuations\n",
    "processed = comments1.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    " \n",
    " #  remove whitespaces\n",
    "processed = processed.str.replace(r'\\s+', ' ')\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " #  kower case\n",
    "processed = processed.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " #  remove stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"turkish\"))\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    " #  tokenize\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for message in processed:\n",
    "    words = word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "        \n",
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bir', 76697), ('ürün', 59949), ('güzel', 46639), ('iyi', 37133), ('gayet', 25678), ('ederim', 25090), ('tavsiye', 23612), ('hızlı', 21261), ('kaliteli', 19629), ('geldi', 18598), ('aldım', 17440), ('teşekkürler', 17405), ('kargo', 17381), ('olarak', 14037), ('yok', 13638)]\n"
     ]
    }
   ],
   "source": [
    "print(all_words.most_common(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    " #  most common words\n",
    "word_features = []\n",
    "for i in range(1500):\n",
    "    word_features.append(all_words.most_common()[:1500][i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"common_words.txt\", \"w\", encoding=\"utf-8\") as txt_file: # take most common words\n",
    "    for line in word_features:\n",
    "        txt_file.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bir</th>\n",
       "      <th>ürün</th>\n",
       "      <th>iyi</th>\n",
       "      <th>güzel</th>\n",
       "      <th>değil</th>\n",
       "      <th>tavsiye</th>\n",
       "      <th>geldi</th>\n",
       "      <th>gayet</th>\n",
       "      <th>aldım</th>\n",
       "      <th>yok</th>\n",
       "      <th>...</th>\n",
       "      <th>lira</th>\n",
       "      <th>piller</th>\n",
       "      <th>gelirsek</th>\n",
       "      <th>yaşıyorum</th>\n",
       "      <th>iyiki</th>\n",
       "      <th>geçmeden</th>\n",
       "      <th>şöyle</th>\n",
       "      <th>sorunlu</th>\n",
       "      <th>mutfak</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bir   ürün    iyi  güzel  değil  tavsiye  geldi  gayet  aldım    yok  \\\n",
       "0  False  False   True  False  False    False  False  False  False  False   \n",
       "1  False  False   True  False  False    False  False  False  False  False   \n",
       "2  False  False  False  False  False     True  False  False  False  False   \n",
       "3  False  False  False  False  False    False   True  False  False  False   \n",
       "4   True  False  False  False   True    False  False  False  False  False   \n",
       "\n",
       "   ...   lira  piller  gelirsek  yaşıyorum  iyiki  geçmeden  şöyle  sorunlu  \\\n",
       "0  ...  False   False     False      False  False     False  False    False   \n",
       "1  ...  False   False     False      False  False     False  False    False   \n",
       "2  ...  False   False     False      False  False     False  False    False   \n",
       "3  ...  False   False     False      False  False     False  False    False   \n",
       "4  ...  False   False     False      False  False     False  False    False   \n",
       "\n",
       "   mutfak  target  \n",
       "0   False       0  \n",
       "1   False       1  \n",
       "2   False       0  \n",
       "3   False       0  \n",
       "4   False       0  \n",
       "\n",
       "[5 rows x 1501 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17998, 1501)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop([\"target\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.values \n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()  \n",
    "model.add(tf.keras.layers.Flatten())  \n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  \n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  \n",
    "model.add(tf.keras.layers.Dense(2, activation=tf.nn.softmax))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(x).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.3837 - accuracy: 0.8333\n",
      "Epoch 2/3\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 0.2570 - accuracy: 0.8925\n",
      "Epoch 3/3\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.1739 - accuracy: 0.9314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17dbb18fc10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(x, y, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features_1 = pd.read_csv(\"common_words.txt\", header=None)\n",
    "word_features = list(word_features_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " #  find features function\n",
    "\n",
    "def find_features(message):\n",
    "    words = word_tokenize(message)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "deneme = \"çok işime yaradı, beğendim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olumlu yorum\n"
     ]
    }
   ],
   "source": [
    "deneme1 = find_features(deneme)\n",
    "aa = []\n",
    "bb = []\n",
    "for key, value in deneme1.items() :\n",
    "    aa.append(key)\n",
    "    bb.append(value)\n",
    "temel=pd.DataFrame([bb],columns=aa)\n",
    "a = model.predict(temel)\n",
    "if (a[0][0] > a[0][1]+0.1):\n",
    "    print(\"olumsuz yorum\")\n",
    "elif(a[0][1] > a[0][0]+0.1):\n",
    "    print(\"olumlu yorum\")\n",
    "else:\n",
    "    print(\"nötr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13977213 0.86022794]]\n"
     ]
    }
   ],
   "source": [
    "print(a) # %86 olumlu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
